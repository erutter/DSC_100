{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10c523bb",
   "metadata": {},
   "source": [
    "# Lab 02: Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdef824",
   "metadata": {},
   "source": [
    "In this lab, you will review how to create DataFrames and extract information from them. The first part of the lab will be a review of commands we have learned from lecture and some questions to help you solidify your ```pandas``` knowledge. \n",
    "\n",
    "In the second part of the lab, you will work with real datasets to answer some questions using your DSC 8 knowledge, but with ```pandas```. The purpose of this assignment is for you to combine Python, math, and the ideas in Data 8 to draw some interesting conclusions. The methods and results will help build the foundation of Data 100.\n",
    "\n",
    "## Score Breakdown\n",
    "Question | Points| Question | Points\n",
    "--- | --- | --- | ---\n",
    "1a | 2   | 3 |  7\n",
    "1b | 2   | 4a | 2\n",
    "1c | 2   | 4b | 2\n",
    "1d | 2   | 4c | 2\n",
    "1d |  2  | 4d | 7\n",
    "2a | 2   | 4e | 2\n",
    "2b | 2   | 4f | 2\n",
    "2c |  2   | 4g | 2\n",
    "2d | 2\n",
    "2e | 2\n",
    "Total |   | 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92123cc8",
   "metadata": {},
   "source": [
    "## Collaboration Policy\n",
    "\n",
    "Data science is a collaborative activity. While you may talk with others about the labs, we ask that you **write your solutions individually**. If you do discuss the assignments with others please **include their names** below. (It's a good way to learn your classmates' names too!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9739df",
   "metadata": {},
   "source": [
    "**Collaborators**: *list collaborators here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d5b40d",
   "metadata": {},
   "source": [
    "---\n",
    "[Pandas](https://pandas.pydata.org/) is one of the most widely used Python libraries in data science. In this lab, you will review commonly used data-wrangling operations/tools in `pandas`. We aim to give you familiarity with:\n",
    "\n",
    "* Creating `DataFrames`,\n",
    "* Slicing `DataFrames` (i.e., selecting rows and columns)\n",
    "* Filtering data (using boolean arrays)\n",
    "\n",
    "In this lab, you are going to use several `pandas` methods. Reminder from lecture that you may press `shift+tab` on method parameters to see the documentation for that method. For example, if you were using the `drop` method in `pandas`, you could press `shift+tab` to see what `drop` is expecting.\n",
    "\n",
    "`pandas` is very similar to the `datascience` library that you saw in Data 8. This [conversion notebook](https://data100.datahub.berkeley.edu/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2FDS-100%2Fsu23-materials&branch=main&urlpath=lab%2Ftree%2Fsu23-materials%2Flec%2Flec02%2Fdata8_translation_examples.ipynb) may serve as a useful guide!\n",
    "\n",
    "This lab expects that you have watched the `Pandas I` and `II` lectures. If you have not, this lab will probably take a very long time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3c64af",
   "metadata": {},
   "source": [
    "**Note**: The `pandas` interface is notoriously confusing for beginners, and the documentation is not consistently great. Throughout the semester, you will have to search through `pandas` documentation and experiment, but remember it is part of the learning experience and will help shape you as a data scientist!\n",
    "\n",
    "**This assignment seems long, but rest assured that a large part of it is a tutorial (i.e., we will guide you through many aspects of using `pandas` in the most efficient way possible!).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce30fef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85476fa",
   "metadata": {},
   "source": [
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "# PART 1: ```PANDAS``` REVIEW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca75eeb8",
   "metadata": {},
   "source": [
    "## **REVIEW:** Creating `DataFrames` & Basic Manipulations\n",
    "\n",
    "Recall that a [DataFrame](https://pandas.pydata.org/pandas-docs/stable/user_guide/dsintro.html#dataframe) is a table in which each column has a specific data type; there is an index over the columns (typically string labels) and an index over the rows (typically ordinal numbers).\n",
    "\n",
    "Usually, you'll create `DataFrames` by using a function like `pd.read_csv`. However, in this section, we'll discuss how to create them from scratch.\n",
    "\n",
    "The [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html) for the `pandas` `DataFrame` class provides several constructors for the `DataFrame` class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc995b5",
   "metadata": {},
   "source": [
    "**Syntax 1:** You can create a `DataFrame` by specifying the columns and values using a dictionary, as shown below. \n",
    "\n",
    "The keys of the dictionary are the column names, and the values of the dictionary are lists containing the row entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1b307b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_info = pd.DataFrame(\n",
    "    data = {'fruit': ['apple', 'orange', 'banana', 'raspberry'],\n",
    "          'color': ['red', 'orange', 'yellow', 'pink'],\n",
    "          'price': [1.0, 0.75, 0.35, 0.05]\n",
    "          })\n",
    "fruit_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e18b18b",
   "metadata": {},
   "source": [
    "**Syntax 2:** You can also define a `DataFrame` by specifying the rows as shown below. \n",
    "\n",
    "Each row corresponds to a distinct tuple, and the columns are specified separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d37a50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_info2 = pd.DataFrame(\n",
    "    [(\"red\", \"apple\", 1.0), (\"orange\", \"orange\", 0.75), (\"yellow\", \"banana\", 0.35),\n",
    "     (\"pink\", \"raspberry\", 0.05)], \n",
    "    columns = [\"color\", \"fruit\", \"price\"])\n",
    "fruit_info2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44452468",
   "metadata": {},
   "source": [
    "You can obtain the dimensions of a `DataFrame` by using the shape attribute `DataFrame.shape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeddb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_info.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ee1874",
   "metadata": {},
   "source": [
    "You can also convert the entire `DataFrame` into a two-dimensional `NumPy` array. Remember that a `NumPy` array can hold homogenous data whereas a `DataFrame` can contain heterogeneous data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e247da",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = pd.DataFrame({\"A\":[1, 2, 3], \"B\":[0, 1, 1]})\n",
    "numpy_numbers = numbers.to_numpy()\n",
    "\n",
    "print(type(numpy_numbers))\n",
    "print(numpy_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fee54ff",
   "metadata": {},
   "source": [
    "The `values` attribute returns the content of the `DataFrame` in the form of a list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c7a377",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_info.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2063d81",
   "metadata": {},
   "source": [
    "There are other constructors but we will not discuss them here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852b158f",
   "metadata": {},
   "source": [
    "## **REVIEW:** Selecting Rows and Columns in `pandas`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89da26b8",
   "metadata": {},
   "source": [
    "As you've seen in lecture, there are two verbose operators in Python for selecting rows: `loc` and `iloc`. Let's review them briefly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f61bd5",
   "metadata": {},
   "source": [
    "**Approach 1:** `loc`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84eb9818",
   "metadata": {},
   "source": [
    "The first of the two verbose operators is `loc`, which takes two arguments. The first is one or more **row labels**, the second is one or more **column labels** - both of which are displayed in bold to the left of each of the rows and above each of the columns, respectively. These are not the same as positional indices, which are used for indexing Python lists or `NumPy` arrays!\n",
    "\n",
    "The desired rows or columns can be provided individually, in slice notation, or as a list. Some examples are given below.\n",
    "\n",
    "Note that **slicing in `loc` is inclusive** on the provided labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639761a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rows 0 through 2 (inclusive) with labels 'fruit' through 'price' (which would include the color column that is in between both labels)\n",
    "fruit_info.loc[0:2, 'fruit':'price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37503a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rows 0 through 2 (inclusive) and columns 'fruit' and 'price'. \n",
    "# Note the difference in notation and result from the previous example.\n",
    "fruit_info.loc[0:2, ['fruit', 'price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116b3366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rows 0 and 2 and columns fruit and price. \n",
    "fruit_info.loc[[0, 2], ['fruit', 'price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b2ca00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rows 0 and 2 and column fruit\n",
    "fruit_info.loc[[0, 2], ['fruit']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c0a670",
   "metadata": {},
   "source": [
    "Note that if we request a single column but don't enclose it in a list, the return type of the `loc` operator is a `Series` rather than a `DataFrame`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a11aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rows 0 and 2 and column fruit, returning the result as a Series\n",
    "fruit_info.loc[[0, 2], 'fruit']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ac7342",
   "metadata": {},
   "source": [
    "If we provide only one argument to `loc`, it uses the provided argument to select rows, and returns all columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7706065",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_info.loc[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ae1d2c",
   "metadata": {},
   "source": [
    "Note that if you try to access columns without providing rows, `loc` will crash. Uncomment the following codes individually to try them and out and become familiar with the types of error message. Then, comment them back up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af924634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment, this code will crash\n",
    "#fruit_info.loc[[\"fruit\", \"price\"]]\n",
    "\n",
    "# Uncomment, this code works fine: \n",
    "#fruit_info.loc[:, [\"fruit\", \"price\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e2f563",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "**Approach 2:** `iloc`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10eff59",
   "metadata": {},
   "source": [
    "`iloc` is very similar to `loc` except that its arguments are **row numbers** and **column numbers**, rather than row and column labels. A useful mnemonic is that the `i` stands for \"integer\". This is quite similar to indexing into a Python `list` or `NumPy` array.\n",
    "\n",
    "In addition, **slicing for `iloc` is exclusive** on the provided integer indices. Some examples are given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefa7395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rows 0 through 3 (exclusive) and columns 0 through 3 (exclusive)\n",
    "fruit_info.iloc[0:3, 0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384a9715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rows 0 through 3 (exclusive) and columns 0 and 2.\n",
    "fruit_info.iloc[0:3, [0, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64df0f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rows 0 and 2 and columns 0 and 2.\n",
    "fruit_info.iloc[[0, 2], [0, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3981867a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rows 0 and 2 and column fruit\n",
    "fruit_info.iloc[[0, 2], [0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e60b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rows 0 and 2 and column fruit\n",
    "fruit_info.iloc[[0, 2], 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a94f9e",
   "metadata": {},
   "source": [
    "Note that in these `loc` and `iloc` examples above, the row **label** and row **number** were always the same.\n",
    "\n",
    "Let's see an example where they are different. If we sort our fruits by price, we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f3389c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_info_sorted = fruit_info.sort_values(\"price\")\n",
    "fruit_info_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95abdc7",
   "metadata": {},
   "source": [
    "After sorting, note how row number 0 now has index label 3, row number 1 now has index label 2, etc. These indices are the arbitrary numerical indices generated when we created the `DataFrame`. For example, `banana` was originally in row 2, and so it has row label 2. Note the distinction between the index _label_, and the actual index _position_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693e0cca",
   "metadata": {},
   "source": [
    "If we request the rows in positions 0 and 2 using `iloc`, we're indexing using the row NUMBERS, not labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fce0a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_info_sorted.iloc[[0, 2], 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ec94a1",
   "metadata": {},
   "source": [
    "Lastly, similar to `loc`, the second argument to `iloc` is optional. That is, if you provide only one argument to `iloc`, it treats the argument you provide as a set of desired row numbers, not column numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d178540",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_info_sorted.iloc[[0, 2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae19c633",
   "metadata": {},
   "source": [
    "**Approach 3:** `[]` Notation for Accessing Rows and Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adce26e",
   "metadata": {},
   "source": [
    "`pandas` also supports the `[]` operator. It's similar to `loc` in that it lets you access rows and columns by their name.\n",
    "\n",
    "However, unlike `loc`, which takes row names and also optionally column names, `[]` is more flexible. If you provide it only row names, it'll give you rows (same behavior as `loc`), and if you provide it with only column names, it'll give you columns (whereas `loc` will crash).\n",
    "\n",
    "Some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd9d5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_info[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b821c641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we're providing a list of fruits as single argument to []\n",
    "fruit_info[[\"fruit\", \"color\", \"price\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77da6e21",
   "metadata": {},
   "source": [
    "Note that slicing notation is not supported for columns if you use `[]` notation. Use `loc` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b69070c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and this code crashes\n",
    "#fruit_info[\"fruit\":\"price\"]\n",
    "\n",
    "# Uncomment and this works fine\n",
    "#fruit_info.loc[:, \"fruit\":\"price\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c348f4d",
   "metadata": {},
   "source": [
    "`[]` and `loc` are quite similar. For example, the following two pieces of code are functionally equivalent for selecting the fruit and price columns.\n",
    "\n",
    "1. `fruit_info[[\"fruit\", \"price\"]]` \n",
    "2. `fruit_info.loc[:, [\"fruit\", \"price\"]]`.\n",
    "\n",
    "Because it yields more concise code, you'll find that our code and your code both tend to feature `[]`. However, there are some subtle pitfalls of using `[]`. If you're ever having performance issues, weird behavior, or you see a `SettingWithCopyWarning` in `pandas`, switch from `[]` to `loc`, and this may help.\n",
    "\n",
    "To avoid getting too bogged down in indexing syntax, we'll avoid a more thorough discussion of `[]` and `loc`. We may return to this at a later point in the course.\n",
    "\n",
    "For more on `[]` vs. `loc`, you may optionally try reading:\n",
    "1. https://stackoverflow.com/questions/48409128/what-is-the-difference-between-using-loc-and-using-just-square-brackets-to-filte\n",
    "2. https://stackoverflow.com/questions/38886080/python-pandas-series-why-use-loc/65875826#65875826\n",
    "3. https://stackoverflow.com/questions/20625582/how-to-deal-with-settingwithcopywarning-in-pandas/53954986#53954986"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52352e37",
   "metadata": {},
   "source": [
    "Now that we've reviewed basic indexing, let's discuss how we can modify `DataFrames`. We'll do this via a series of exercises. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8ac95e",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 1a\n",
    "\n",
    "For a `DataFrame` `d`, you can add a column with `d['new column name'] = ...` and assign a `list` or `array` of values to the column. Add a column of integers containing 1, 2, 3, and 4 called `rank1` to the `fruit_info` table, which expresses **your personal preference** about the taste ordering for each fruit (1 is tastiest; 4 is least tasty). There is no right order, it is completely your choice of rankings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7852fb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "fruit_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5660929a",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 1b\n",
    "\n",
    "You can also add a column to `d` with `d.loc[:, 'new column name'] = ...`. As above, the first parameter is for the rows, and the second is for columns. The `:` means changing all rows, and the `'new column name'` indicates the name of the column you are modifying (or, in this case, adding). \n",
    "\n",
    "Add a column called `rank2` to the `fruit_info` table, which contains the same values in the same order as the `rank1` column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1495b7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "fruit_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1221d0d6",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 1c\n",
    "\n",
    "Use the `.drop()` method to [drop](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html) both the `rank1` and `rank2` columns you created. Make sure to use the `axis` parameter correctly. Note that `drop` does not change a table but instead returns a new table with fewer columns or rows unless you set the optional `inplace` argument.\n",
    "\n",
    "**Hint:** Look through the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html) to see how you can drop multiple columns of a `DataFrame` at once using a list of column names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e38916",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_info_original = ...\n",
    "fruit_info_original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a74eca",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 1d\n",
    "\n",
    "Use the `.rename()` method to rename the columns of `fruit_info_original` so they begin with capital letters. Set this new `DataFrame` to `fruit_info_caps`. For an example of how to use rename, see this linked [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rename.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68ec8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "fruit_info_caps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8942be",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "\n",
    "## Babynames Dataset\n",
    "For the next few questions of this lab, let's move on to a real-world dataset. We'll be using the babynames dataset from Lecture 3. The babynames dataset contains a record of the given names of babies born in the United States each year.\n",
    "\n",
    "Let's run the following cells to build the `DataFrame` `babynames`. Note that we only include data from California due to memory constraints (the full dataset has over 6 million rows!). There should be a total of 407428 records.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2aebc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/namesbystate_ca.txt.gz'\n",
    "column_labels = ['State', 'Sex', 'Year', 'Name', 'Count']\n",
    "\n",
    "babynames = pd.read_csv(file_path, names=column_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64f5e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(babynames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5518957c",
   "metadata": {},
   "outputs": [],
   "source": [
    "babynames.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2229aa7f",
   "metadata": {},
   "source": [
    "## Selection Examples on Baby Names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70947a2f",
   "metadata": {},
   "source": [
    "As with our synthetic fruit dataset, we can use `loc` and `iloc` to select rows and columns of interest from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e11e911",
   "metadata": {},
   "outputs": [],
   "source": [
    "babynames.loc[2:5, 'Name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4698e70",
   "metadata": {},
   "source": [
    "Notice the difference between the following cell and the previous one; just passing in `'Name'` returns a `Series` while `['Name']` returns a `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ad7157",
   "metadata": {},
   "outputs": [],
   "source": [
    "babynames.loc[2:5, ['Name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3065f60d",
   "metadata": {},
   "source": [
    "The code below collects the rows in positions 1 through 3, and the column in position 3 (\"Name\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075c3868",
   "metadata": {},
   "outputs": [],
   "source": [
    "babynames.iloc[1:4, [3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25b4a0b",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 2a\n",
    "\n",
    "Use `.loc` to select `Name` and `Year` **in that order** from the `babynames` table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d86d2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_and_year = ...\n",
    "name_and_year[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1385f0b3",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 2b\n",
    "Now repeat the same selection using the plain `[]` notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48def8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_and_year = ...\n",
    "name_and_year[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f489d315",
   "metadata": {},
   "source": [
    "## **REVIEW**: Filtering with boolean arrays\n",
    "\n",
    "Filtering is the process of removing unwanted entries. In your quest for cleaner data, you will undoubtedly filter your data at some point: whether it be for clearing up cases with missing values, for culling out fishy outliers, or for analyzing subgroups of your dataset. Example usage looks like `df[df['column name'] < 5]`.\n",
    "\n",
    "For your reference, some commonly used comparison operators are given below.\n",
    "\n",
    "Symbol | Usage      | Meaning \n",
    "------ | ---------- | -------------------------------------\n",
    "==   | a == b   | Does a equal b?\n",
    "<=   | a <= b   | Is a less than or equal to b?\n",
    "&gt;=   | a >= b   | Is a greater than or equal to b?\n",
    "<    | a < b    | Is a less than b?\n",
    "&#62;    | a &#62; b    | Is a greater than b?\n",
    "~    | ~p       | Returns negation of p\n",
    "&#124; | p &#124; q | p OR q\n",
    "&    | p & q    | p AND q\n",
    "^  | p ^ q | p XOR q (exclusive or)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d776ae45",
   "metadata": {},
   "source": [
    "As an example, in the following, we construct a `DataFrame` containing only rows where the name is Arman."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39bf839",
   "metadata": {},
   "outputs": [],
   "source": [
    "arman_babynames = babynames[babynames['Name'] == 'Arman']\n",
    "arman_babynames.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe96f5d",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "---\n",
    "## Question 2c\n",
    "Using a boolean array, select the names in Year 2000 (from `babynames`) that have larger than 3000 counts. Keep all columns from the original `babynames` `DataFrame`.\n",
    "\n",
    "_Note_: Note that compound expressions have to be grouped with parentheses. That is, any time you use `p & q` to filter the `DataFrame`, make sure to use `df[(df[p]) & (df[q])]` or `df.loc[(df[p]) & (df[q])]`. \n",
    "\n",
    "You may use either `[]` or `loc`. Both will achieve the same result. For more on `[]` vs. `loc`, see the stack overflow links from the intro portion of this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664dd578",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ...\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a494ea5",
   "metadata": {},
   "source": [
    "## **REVIEW:** `str`\n",
    "\n",
    "`pandas` provides special purpose functions for working with specific common data types such as strings and dates. For example, the code below provides the length of every baby's name from our `babynames` dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a8b3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "babynames['Name'].str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3250d6c9",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6461f8",
   "metadata": {},
   "source": [
    "Add a column to `babynames` named `First Letter` that contains the first letter of each baby's name.\n",
    "\n",
    "Hint: you can index using `.str` similarly to how you'd normally index Python strings. Or, you can use `.str.get` [(documentation here)](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.get.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703ffee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "babynames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4015eb",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 2e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c8329b",
   "metadata": {},
   "source": [
    "In 2022, how many babies had names that started with the letter \"A\"? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2a8e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "babynames_2022 = ...\n",
    "just_A_names_2022 = ...\n",
    "number_A_names = ...\n",
    "number_A_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a24be97",
   "metadata": {},
   "source": [
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "# PART 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62debbcf",
   "metadata": {},
   "source": [
    "In this second part of the lab, you will work with real data sets to investigate health questions. We will work on data analysis and plotting using built-in python libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa5de40",
   "metadata": {},
   "source": [
    "### Initialize your environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dfea90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c87d72",
   "metadata": {},
   "source": [
    "### Preliminary: Jupyter Shortcuts ###\n",
    "\n",
    "Here are some useful Jupyter notebook keyboard shortcuts.  To learn more keyboard shortcuts, go to **Help -> Keyboard Shortcuts** in the menu above. \n",
    "\n",
    "Here are a few we like:\n",
    "1. `ctrl`+`return` : *run the current cell*\n",
    "1. `shift`+`return`: *run the current cell and move to the next*\n",
    "1. `esc` : *command mode* (may need to press before using any of the commands below)\n",
    "1. `a` : *create a cell above*\n",
    "1. `b` : *create a cell below*\n",
    "1. `dd` : *delete a cell*\n",
    "1. `m` : *convert a cell to markdown*\n",
    "1. `y` : *convert a cell to code*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e206f5a",
   "metadata": {},
   "source": [
    "### Preliminary: `NumPy` ###\n",
    "\n",
    "You should be able to understand the code in the following cells. If not, review the following:\n",
    "\n",
    "* [Data 8 Textbook Chapter on NumPy](https://www.inferentialthinking.com/chapters/05/1/Arrays)\n",
    "* [DS100 NumPy Review](http://ds100.org/fa17/assets/notebooks/numpy/Numpy_Review.html)\n",
    "* [Condensed NumPy Review](http://cs231n.github.io/python-numpy-tutorial/#numpy)\n",
    "* [The Official NumPy Tutorial](https://numpy.org/doc/stable/user/quickstart.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88db36e1",
   "metadata": {},
   "source": [
    "**Jupyter pro-tip**: Pull up the documentation for any function in Jupyter by running a cell with\n",
    "the function name and a `?` at the end:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bccc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fb33ef",
   "metadata": {},
   "source": [
    "**Another Jupyter pro-tip**: Pull up the documentation for any function in Jupyter by typing the function\n",
    "name, then `<Shift><Tab>` on your keyboard. This is super convenient when you forget the order\n",
    "of the arguments to a function. You can press `<Tab>` multiple times to expand the docs and reveal additional information.\n",
    "\n",
    "Try it on the function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9d09ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0cb60c",
   "metadata": {},
   "source": [
    "### Preliminary: LaTeX ###\n",
    "You should use LaTeX to format math in your answers. If you aren't familiar with LaTeX, don't worry. It's not hard to use in a Jupyter notebook. Just place your math in between dollar signs within Markdown cells:\n",
    "\n",
    "`$ f(x) = 2x $` becomes $ f(x) = 2x $.\n",
    "\n",
    "If you have a longer equation, use double dollar signs to place it on a line by itself:\n",
    "\n",
    "`$$ \\sum_{i=0}^n i^2 $$` becomes:\n",
    "\n",
    "$$ \\sum_{i=0}^n i^2$$\n",
    "\n",
    "\n",
    "You can align multiple lines using the `&` anchor, `\\\\` newline, in an `align` block as follows:\n",
    "\n",
    "```\n",
    "\\begin{align}\n",
    "f(x) &= (x - 1)^2 \\\\\n",
    "&= x^2 - 2x + 1\n",
    "\\end{align}\n",
    "```\n",
    "becomes\n",
    "\n",
    "\\begin{align}\n",
    "f(x) &= (x - 1)^2 \\\\\n",
    "&= x^2 - 2x + 1\n",
    "\\end{align}\n",
    "\n",
    "* [This PDF](latex_tips.pdf) has some handy LaTeX tips.\n",
    "* [For more about basic LaTeX formatting, you can read this article.](https://www.sharelatex.com/learn/Mathematical_expressions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f3753a",
   "metadata": {},
   "source": [
    "### Preliminary: Sums ###\n",
    "\n",
    "Here's a recap of some basic algebra written in sigma notation. The facts are all just applications of the ordinary associative and distributive properties of addition and multiplication, written compactly and without the possibly ambiguous \"$\\dots$\". But if you are ever unsure of whether you're working correctly with a sum, you can always try writing $\\sum_{i=1}^n a_i$ as $a_1 + a_2 + \\cdots + a_n$ and see if that helps.\n",
    "\n",
    "You can use any reasonable notation for the index over which you are summing, just as in Python you can use any reasonable name in `for name in list`. Thus $\\sum_{i=1}^n a_i = \\sum_{k=1}^n a_k$.\n",
    "\n",
    "- $\\sum_{i=1}^n (a_i + b_i) = \\sum_{i=1}^n a_i + \\sum_{i=1}^n b_i$\n",
    "- $\\sum_{i=1}^n d = nd$\n",
    "- $\\sum_{i=1}^n (ca_i + d) = c\\sum_{i=1}^n a_i + nd$\n",
    "\n",
    "These properties may be useful in the future when we cover Least Squares Predictors. To see the LaTeX we used, double-click this cell. Evaluate the cell to exit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb596256",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 1: Distributions ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefce612",
   "metadata": {},
   "source": [
    "Visualizing distributions, both categorical and numerical, helps us understand variability. In Data 8, you visualized numerical distributions by drawing histograms ([Chapter 7.2 link](https://inferentialthinking.com/chapters/07/2/Visualizing_Numerical_Distributions.html#histogram)), which look like bar charts but represent proportions through the *areas* of the bars instead of the heights or lengths.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f88410",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Part 0: Matplotlib Tutorial\n",
    "\n",
    "We will not be using Data 8's `datascience` library in this course. Instead, we will learn industry——and academia——standard libraries for exploring and visualizing data, including `matplotlib` ([official website](https://matplotlib.org/)).\n",
    "In this exercise, you will use the `hist` function in `matplotlib` instead of the corresponding `Table` method to draw histograms. In a previous cell, we imported the matplotlib library as `plt`, which allows us to call `plt.hist()`.\n",
    "\n",
    "To start off, suppose we want to plot the probability distribution of the number of spots on a single roll of a die. That should be a flat histogram since the chance of each of the values 1 through 6 is $\\frac{1}{6}$. Here is a first attempt at drawing the histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a6f215",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = range(1, 7)\n",
    "plt.hist(faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c092b5",
   "metadata": {},
   "source": [
    "This default plot is not helpful. We have to choose some arguments to get a visualization that we can interpret. \n",
    "\n",
    "Note that the second printed line shows the left ends of the default bins, as well as the right end of the last bin. The first line shows the counts in the bins. If you don't want the printed lines, you can add a semi-colon `;` at the end of the call to `plt.hist`, but we'll keep the lines for now.\n",
    "\n",
    "Let's redraw the histogram with bins of unit length centered at the possible values. By the end of the tutorial, you'll see a reason for centering. Notice that the argument for specifying bins is the same as the one for the `Table` method `hist` from the `datascience` library in DSC 8 ([link](https://www.data8.org/datascience/reference-nb/datascience-reference.html#tbl.hist()))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff4b156",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_bins = np.arange(0.5, 6.6)\n",
    "plt.hist(faces, bins=unit_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df13ff7",
   "metadata": {},
   "source": [
    "We need to see the edges of the bars! Let's specify the edge color `ec` to be `white`. [Here](https://matplotlib.org/3.5.3/gallery/color/named_colors.html) are all the colors you could use, but do try to drag yourself away from the poetic names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d204c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(faces, bins=unit_bins, ec='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030d9630",
   "metadata": {},
   "source": [
    "That's much better, but look at the vertical axis. It is not drawn to the density scale defined in Data 8 ([Chapter 7.2 link](https://inferentialthinking.com/chapters/07/2/Visualizing_Numerical_Distributions.html#the-vertical-axis-density-scale)). We want a histogram of a probability distribution, so the total area should be 1. We just have to ask for that by setting `density` to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d1d192",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(faces, bins=unit_bins, ec='white', density=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17a269d",
   "metadata": {},
   "source": [
    "That's the probability histogram of the number of spots on one roll of a die. The proportion is $\\frac{1}{6}$ in each of the bins."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5392c1bd",
   "metadata": {},
   "source": [
    "Finally, we can set the opacity, or transparency, of the bars with the `alpha` parameter, which is a value from 0 to 1. For 70% opacity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba536aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(faces, bins=unit_bins, ec='white', density=True, alpha=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da427e7",
   "metadata": {},
   "source": [
    "**Note/Reminder**: The above cells printed the counts/proportions and bin boundaries with the visualization. This was intentional on our part to show you how `plt.hist()` returned different values per plot. You may use a semicolon `;` on the last line to suppress additional display as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe59f938",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 3\n",
    "\n",
    "Define a function `plot_distribution` that takes an array of numbers (integers or decimals) and draws the histogram of the distribution using unit bins centered at the integers and white edges for the bars.\n",
    "\n",
    "The histogram should be drawn to the density scale, and the opacity should be 75%. The left-most bar should be centered at the integer closest to the smallest number in the array, and the right-most bar should be centered around the integer closest to the largest number in the array.\n",
    "\n",
    "The display does not need to include the printed proportions and bins. No titles or labels are required for this question. For grading purposes, assign your plot to `histplot`.\n",
    "\n",
    "If you have trouble defining the function, go back and carefully read all the lines of code that resulted in the probability histogram of the number of spots on one roll of a die. Pay special attention to the bins. Feel free to create a cell to test your function on generic arrays to check for correctness!\n",
    "\n",
    "**Hint**: \n",
    "* See `plt.hist()` [documentation](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.hist.html).\n",
    "* We want to: (1) center each bin at integer values and (2) make sure all the values in the array are captured by the bins.\n",
    "    * For example, let’s say we have the following input array: `[0.3, 0.7, 1.1, 1.4, 1.9]`.\n",
    "    * The smallest value is `0.3`; the left endpoint of the leftmost bin (the first bin) should be `-0.5` and the rightmost endpoint of this bin should be `0.5` so that this bin is centered at the integer `0`.\n",
    "    * This first bin above captures `0.3`. The second bin will be centered at `1` (between `0.5` and `1.5`) and captures `0.7`, `1.1`, and `1.4`.\n",
    "    * We can continue in this manner until all values are captured by our bins.\n",
    "* What is the left endpoint of the left-most bar? What is the right endpoint of the right-most bar? You may find `min()`, `max()`, and `round()` helpful.\n",
    "* Please keep in mind your function should be implemented so that it works for _any_ generic array of numbers (integers or decimals), not just the `faces` array in the cell below.\n",
    "* If you implement the function correctly, you should get a plot like this:\n",
    "\n",
    "<img src=\"images/q1a.png\" alt=\"question 1a plot\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfc411b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution(arr):\n",
    "    # Define bins\n",
    "    unit_bins = ...\n",
    "    # Plot the data arr using unit_bins, assign the plot to histplot\n",
    "    histplot = ...\n",
    "    return histplot\n",
    "faces = range(1, 10)\n",
    "histplot = plot_distribution(faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a869fb",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "---\n",
    "\n",
    "### Tutorial: Serum Cholesterol\n",
    "\n",
    "Recall from Data 8 that you can perform [hypothesis testing using the permutation test](https://inferentialthinking.com/chapters/12/1/AB_Testing.html) (Chapter 12.1). **Before continuing, we HIGHLY ENCOURAGE you to read the above linked Data 8 chapters for a review of how hypothesis testing works.**\n",
    "\n",
    "Scientists across several hospitals have gathered data about heart disease and non-disease patients, and they are organized into the following dataset called `hearts_df` (from the `csv` file `hearts.csv`). In this question, we study one recorded feature in `hearts_df`: serum cholesterol. Serum cholesterol refers to the total amount of cholesterol in one’s blood. Further details about the dataset are discussed in [this Kaggle page](https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction).\n",
    "In this assignment, we will investigate whether patients with heart disease have different serum cholesterol levels than patients without heart disease.\n",
    "\n",
    "**Run the below cell**, which assigns `non_disease_chol` to a list of serum cholesterol values of patients without heart disease (of which there are 390), and `disease_chol` to a list of serum cholesterols of patients with heart disease (of which there are 356)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aafa33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell. You will learn these functions soon!\n",
    "\n",
    "import pandas as pd\n",
    "hearts_df = pd.read_csv(\"hearts.csv\")\n",
    "\n",
    "non_disease_chol = hearts_df[hearts_df['HeartDisease'] == 0]['Cholesterol'].values\n",
    "print(len(non_disease_chol))\n",
    "\n",
    "disease_chol = hearts_df[hearts_df['HeartDisease'] == 1]['Cholesterol'].values\n",
    "print(len(disease_chol))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee37b4b",
   "metadata": {},
   "source": [
    "Suppose that we overlay the distributions of cholesterol levels from the two groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfd7f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell. You will learn these functions soon!\n",
    "\n",
    "import seaborn as sns\n",
    "sns.histplot(hearts_df, x=\"Cholesterol\", hue=\"HeartDisease\");\n",
    "plt.title(\"Distribution of Cholesterol Levels\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac01a22",
   "metadata": {},
   "source": [
    "In the plot above, `0` indicates data from patients without heart disease, and `1` indicates data from patients with heart disease. The distribution of serum cholesterol of patients without heart disease is centered slightly left of the distribution corresponding to those with heart disease. Specifically, the **average** serum cholesterol of patients without heart disease appears lower than that of patients with heart disease."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d124b035",
   "metadata": {},
   "source": [
    "<br/>    \n",
    "As mentioned in the introduction of this question, we'd like to study whether this difference reflects just chance variation or perhaps a difference in the distributions in the larger population. Suppose we propose the following two hypotheses:\n",
    "\n",
    "> **Null hypothesis ($\\mathcal{H}_0$)**: In the population, the distribution of serum cholesterol of non-patients is the same for heart disease patients. The (observed) difference in the sample is due to chance.\n",
    "\n",
    "> **Alternative hypothesis ($\\mathcal{H}_1$)**: In the population, the distribution of serum cholesterol of non-patients is **different** from that of heart disease patients.\n",
    "\n",
    "We would like to perform hypothesis testing using the permutation test. One way to do so is to compute an observed test statistic and then compare it with multiple simulated test statistics generated through random permutations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e97c104",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "---\n",
    "## Question 4\n",
    "\n",
    "In this question, we will confirm some details about the hypothesis testing operations proposed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327ab398",
   "metadata": {},
   "source": [
    "### Question 4a\n",
    "Given the study description and hypotheses outlined above, select the statement that most accurately describes the hypothesis test we conducted. Answer this question by entering the letter corresponding to your answer in the textbox below, along with a sentence describing your choice. \n",
    "\n",
    "**A.** The hypothesis test is one-sided.  The null hypothesis is rejected when the average serum cholesterol of patients with heart disease is significantly higher than that of patients without heart disease. \\\n",
    "**B.** The hypothesis test is two-sided because we are comparing the average serum cholesterol of two different groups. \\\n",
    "**C.** The hypothesis test is two-sided. The null hypothesis is rejected when the average serum cholesterol of patients with heart disease is significantly higher or lower than that of patients without heart disease. \\\n",
    "**D.** The hypothesis test is two-sided because the test statistic, the difference in means, is symmetrically distributed. In other words, the two halves of the distribution closely resemble each other, so the test is two-sided.\n",
    "\n",
    "\n",
    "**Hint**: Visit just the first few paragraphs of [this page](https://www.stat.berkeley.edu/~spector/s133/Random1.html) to refresh your knowledge on the differences between \"one-sided\" and \"two-sided\" tests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5815a757",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4300701",
   "metadata": {},
   "source": [
    "### Question 4b\n",
    "​\n",
    "Suppose that we choose a reasonable test statistic as the **absolute difference** between the average cholesterol level of patients with heart disease and the corresponding average for patients without heart disease.\n",
    "In the cell below, assign `observed_difference` to the observed value of the test statistic computed from our original samples: `non_disease_chol` and `disease_chol`.\n",
    "​\n",
    "**Hint**: This test statistic is slightly different from what is presented in the Data 8 textbook, [Chapter 12.1 link](https://inferentialthinking.com/chapters/12/1/AB_Testing.html#the-hypotheses)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaba3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_difference = ...\n",
    "observed_difference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee6b2bf",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 4c\n",
    "\n",
    "Before we write any code, let’s review the idea of hypothesis testing with the permutation test. It follows the procedure below: \n",
    "1. We first simulate the experiment many times (say, 10,000 times) using [random permutation](https://inferentialthinking.com/chapters/12/1/AB_Testing.html#predicting-the-statistic-under-the-null-hypothesis) (i.e., without replacement) (i.e., under the assumption that the null hypothesis is true). This simulated sampling process produces an empirical distribution of many values of a predetermined test statistic (say, 10,000 values). \n",
    "2. Then, we compare our one true observed test statistic to this empirical distribution of simulated test statistics to compute an empirical p-value. \n",
    "3. Finally, we compare this p-value to a particular cutoff threshold (often, 0.05) to decide whether we fail to reject the null hypothesis.\n",
    "\n",
    "In the cell below, answer the following questions:\n",
    "* What does an empirical p-value from a permutation test mean in this particular context of serum cholesterol and having heart disease?\n",
    "* Suppose the empirical p-value is $p=0.15$, and our p-value cutoff threshold is $0.01$. Do we reject or fail to reject the null hypothesis? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55221969",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d628c28",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 4d\n",
    "\n",
    "Now, we begin the permutation test by generating an array called `differences` that contains simulated values of our test statistic from **10,000 permuted samples**. Again, note that our test statistic differs from what is in the Data 8 textbook: we are computing the **absolute** difference between the average cholesterol levels of patients with heart disease and without heart diseases, where labels have been assigned at random (i.e., in a world where the null hypothesis is true, so disease status is arbitrary and should have no effect on cholesterol).\n",
    "\n",
    "**Reminder**: Data 100 does **not** support the `datascience` library, so you should instead use the appropriate functions from the `NumPy` library. Some suggested references: Lab 01 (for a quick `NumPy` tutorial), `NumPy` array indexing/slicing [documentation](https://numpy.org/doc/stable/user/basics.indexing.html), `np.random.choice` [documentation](https://numpy.org/doc/stable/reference/random/generated/numpy.random.choice.html) (in particular, the `size` and `replace` parameters), and `np.append` [documentation](https://numpy.org/doc/stable/reference/generated/numpy.append.html).\n",
    "\n",
    "**Note**: We have provided some optional skeleton code below, but you do not need to follow it. However, please still assign your simulated differences to the array `differences`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed28372",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42) # Do not modify this line.\n",
    "\n",
    "# Create an empty array to hold our simulated differences\n",
    "differences = np.array([]) \n",
    "# Set number of repetitions\n",
    "repetitions = 10000\n",
    "# Combine the two arrays into a single array\n",
    "all_cholestrol = np.append(non_disease_chol, disease_chol)\n",
    "\n",
    "for i in np.arange(repetitions):\n",
    "    # Permute all_cholestrol\n",
    "    shuffled_cholesterols = np.random.choice(all_cholestrol, size=len(all_cholestrol), replace=False)\n",
    "    \n",
    "    # Make the simulated patient and non-patient group\n",
    "    sim_non_disease_chol = shuffled_cholesterols[:len(non_disease_chol)]\n",
    "    sim_disease_chol = shuffled_cholesterols[len(non_disease_chol):]\n",
    "    \n",
    "    # Calculate test statistics\n",
    "    sim_difference = np.abs(np.mean(sim_disease_chol) - np.mean(sim_non_disease_chol))\n",
    "    \n",
    "    # Append the test statistics in differences\n",
    "    differences = ...\n",
    "\n",
    "differences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fa6c4e",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 4e\n",
    "\n",
    "The array `differences` is an empirical distribution of the test statistic simulated under the null hypothesis. This is a prediction about the test statistic, based on the null hypothesis.\n",
    "\n",
    "Use the `plot_distribution` function you defined in an earlier part to plot a histogram of this empirical distribution. Because you are using this function, your histogram should have unit bins, with bars centered at integers. No title or labels are required for this question.\n",
    "\n",
    "**Hint**: This part should be very straightforward.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b31832",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18bba73",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 4f\n",
    "\n",
    "Compute `empirical_p`, the empirical p-value based on `differences`, the empirical distribution of the test statistic, and `observed_difference`, the observed value of the test statistic.\n",
    "\n",
    "**Hint**: \n",
    "* Review the conclusion of the [Data 8 textbook example](https://inferentialthinking.com/chapters/12/1/AB_Testing.html#conclusion-of-the-test) in Chapter 12.1.\n",
    "* There are two main differences between this example and the Data 8 example. The first being that our test statistic is different. The second is that our hypothesis is different. How can you adjust the code from the Data 8 example to calculate `empirical_p`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b082fb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "empirical_p = ...\n",
    "empirical_p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e4975d",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 4g\n",
    "\n",
    "Based on your computed empirical p-value, do we reject or fail to reject the null hypothesis? Use the p-value cutoff proposed in Question 1c of $0.01$, or $1\\%$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b03deec",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809c67f2",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Congratulations! You have finished Lab 1!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
